{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "1zhMIe4G5MB97zFV9G65WFswIfzpiG_3R",
      "authorship_tag": "ABX9TyPHKtv+2HyepWY//MZMct5n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jagadish-samarla/Alternate-Groups/blob/main/product_alternatives.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optional code for mounting Drive and changing working directory"
      ],
      "metadata": {
        "id": "X6HM1TNGbEsL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "8cTgaxR6bQBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import os\n",
        "#os.chdir('/content/drive/MyDrive/Colab Notebooks/predicting_height_of_children')"
      ],
      "metadata": {
        "id": "4jOwfT7NbYVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run this code to install all Prerequisites"
      ],
      "metadata": {
        "id": "QDvnE0XaY944"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "YMfQeVwRY312"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Dependencies"
      ],
      "metadata": {
        "id": "kWZI9FWbZJt1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJAYEhXQaQUZ"
      },
      "outputs": [],
      "source": [
        "import imageio\n",
        "from io import BytesIO\n",
        "import requests\n",
        "from matplotlib import pyplot as plt\n",
        "from urllib.request import urlopen\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "import cv2\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import time\n",
        "from sklearn.cluster import KMeans\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import silhouette_score\n",
        "from tqdm import tqdm\n",
        "from sklearn.compose import ColumnTransformer\n",
        "import re\n",
        "from math import ceil\n",
        "import ast\n",
        "from sklearn.metrics import calinski_harabasz_score, silhouette_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_json_data_from_url(url):\n",
        "  '''this function paginates through domain url and returns json data of entire wibsite\n",
        "  '''\n",
        "  data ={}\n",
        "  #to avoid time taking process let's limit the page count to 50\n",
        "  print('Paginating through domain url')\n",
        "  for i in tqdm(range(1, 20)):\n",
        "    pagintating_url = url+ '/collections/all/products.json?page={}'.format(i)\n",
        "    response = urlopen(pagintating_url)\n",
        "    data_json = json.loads(response.read())\n",
        "    for j,k in data_json.items():\n",
        "      #print(k)\n",
        "      if len(k) == 0:\n",
        "        return data\n",
        "      else:\n",
        "        data[i] = data_json\n",
        "  return data"
      ],
      "metadata": {
        "id": "VhKiVh3p58aj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_json_prod_wise(json_data):\n",
        "  '''this function returns product wise json of entire website\n",
        "  '''\n",
        "  product_json = {}\n",
        "  i = 0\n",
        "  for k,v in json_data.items():\n",
        "    for l,m in v.items():\n",
        "      for item in m:\n",
        "        product_json[i] = item\n",
        "        i+=1\n",
        "  return product_json"
      ],
      "metadata": {
        "id": "YvvJMZkA6fYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_image_url_from_json(json_data):\n",
        "  '''this function takes json data and returns image_url\n",
        "  '''\n",
        "  #required_data = {}\n",
        "  if json_data['images'] == []:\n",
        "    return None\n",
        "  else:\n",
        "    return (json_data['images'][0]['src'])"
      ],
      "metadata": {
        "id": "t-fFO6Cc7FB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_images_from_url(url):\n",
        "  ''' this function takes image url as input and returns images as numpy ndarray\n",
        "  '''\n",
        "  res = urllib.request.urlopen(url)\n",
        "  image_data = np.asarray(bytearray(res.read()), dtype=np.uint8)\n",
        "  image_array = cv2.imdecode(image_data, cv2.IMREAD_COLOR)\n",
        "  return image_array"
      ],
      "metadata": {
        "id": "awrQrjXU6z4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_df_vectorized(text_df):\n",
        "  '''This function returns vectorized form of pandas dataframe of text data\n",
        "  '''\n",
        "  vectorizer_ind = TfidfVectorizer(\n",
        "    max_df = 0.95,\n",
        "    min_df = 0.05,\n",
        "    stop_words=\"english\",\n",
        "  )\n",
        "  for col in text_df.columns: \n",
        "    vectorizer_whole = ColumnTransformer([('title', vectorizer_ind, 'format_title'),\n",
        "                                ('tags', vectorizer_ind, 'tags')])\n",
        "  vectorized_df = vectorizer_whole.fit_transform(text_df)\n",
        "  return vectorized_df"
      ],
      "metadata": {
        "id": "faZWK4hV8MQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_title(title):\n",
        "  '''This function returns title of the product from json\n",
        "  '''\n",
        "  plain_title = re.sub('[^a-zA-Z0-9 ]', ' ', title)\n",
        "  return plain_title.lower()"
      ],
      "metadata": {
        "id": "scvwo0svgT35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_tags_as_plain_text(p_json):\n",
        "  '''This function returns tages of the product from json\n",
        "  '''\n",
        "  tags = p_json['tags']\n",
        "  plain_tags = ' '.join([str(elem) for elem in ast.literal_eval(str(tags))])\n",
        "  plain_tags = re.sub(r'[^a-zA-Z0-9 ]', '', plain_tags)\n",
        "  return plain_tags.lower()"
      ],
      "metadata": {
        "id": "qBwDDU6ED8vh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_best_of_k(min_k, max_k, v_df):\n",
        "  '''This function returns best value of k for k-means clustering by Silhouette Analysis\n",
        "  '''\n",
        "  print('Finding best value of k')\n",
        "  wcss = []\n",
        "  #silhouette = []\n",
        "  #calinski = []\n",
        "  for k in tqdm(range(min_k, max_k)):\n",
        "    km = KMeans(n_clusters = k, init=\"k-means++\", n_init = 'auto', random_state = 1234, max_iter=50)\n",
        "    km.fit(v_df)\n",
        "    wcss.append(km.inertia_)\n",
        "    #silhouette.append(silhouette_score(v_df, km.labels_))\n",
        "    #x = v_df.toarray()\n",
        "    #calinski.append(calinski_harabasz_score(x, km.labels_))\n",
        "  wcss_series = pd.Series(wcss, index = range(min_k, max_k))\n",
        "  #calinski_series = pd.Series(calinski, index = range(min_k, max_k))\n",
        "  #silhouette_series = pd.Series(silhouette, index = range(min_k, max_k))\n",
        "  #metric_df = pd.DataFrame([wcss_series, calinski_series, silhouette_series ], columns = ['wcss', 'calinski', 'silhouette'])\n",
        "  best_k = wcss_series[wcss_series.diff(periods=-1)>2].reset_index(drop=True).idxmin()\n",
        "  print('Found best value of k at {}'.format(best_k))\n",
        "  #return wcss_series, calinski_series, silhouette_series, silhouette_series.idxmax()\n",
        "  return best_k"
      ],
      "metadata": {
        "id": "bTutlMryJFji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mapping_title_to_url(url, json_handle):\n",
        "  '''This function returns product url from the title\n",
        "  '''\n",
        "  #title_part = re.sub(' ', '-', title.lower())\n",
        "  product_url = url + '/products/'+ json_handle\n",
        "  return product_url"
      ],
      "metadata": {
        "id": "IEsESAYYIDqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_prod_dataframe(p_df, dom_url):\n",
        "  '''This function returns detailed dataframe of required fields for k-means clustering\n",
        "  '''\n",
        "  p_df['title'] = p_df['prod_json'].apply(lambda x: x['title'] if x else None)\n",
        "  p_df['format_title'] = p_df['title'].apply(lambda x: format_title(x))\n",
        "  p_df['handle'] = p_df['prod_json'].apply(lambda x: x['handle'] if x else None)\n",
        "  p_df['tags'] = p_df['prod_json'].apply(lambda x: get_tags_as_plain_text(x) if x else None)\n",
        "  p_df['product_url'] = p_df['handle'].apply(lambda x: mapping_title_to_url(dom_url, x))\n",
        "  #data_df['Image_url'] = data_df.prod_json.apply(lambda x: get_image_url_from_json(x))\n",
        "  #data_df['Image_array'] = data_df.Image_url.apply(lambda x: get_images_from_url(x))\n",
        "  p_df = p_df.dropna(axis=0)\n",
        "  p_df = p_df.drop_duplicates(subset=['handle'], keep='last')\n",
        "  return p_df"
      ],
      "metadata": {
        "id": "lY3a08FwZDb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_clustering_dict(df): \n",
        "  '''This function culsters the products and returns in dict \n",
        "  '''\n",
        "  alt = df.groupby('cluster_id', sort=True)['product_url'].apply(list).to_dict()\n",
        "  cluster_dict = {}\n",
        "  for k, v in alt.items():\n",
        "    cluster_dict['product alternates {}'.format(int(k)+1)] = v\n",
        "  return cluster_dict"
      ],
      "metadata": {
        "id": "uSYcIy9pa_yp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def FindAlternateGroups(store_domain_url):\n",
        "  '''This is the core function.\n",
        "     This function takes store domain url as input \n",
        "     and returns product title & image array as key& value pairs of python dictionary \n",
        "  '''\n",
        "  paginated_json_data=get_json_data_from_url(store_domain_url)\n",
        "  prod_wise_json = get_json_prod_wise(paginated_json_data)\n",
        "  prod_series = pd.Series(list(prod_wise_json.values()))\n",
        "  data_df = pd.DataFrame(prod_series, columns=['prod_json'])\n",
        "  return data_df, store_domain_url"
      ],
      "metadata": {
        "id": "6Fo2NWOF7T3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Replace Domain URL here\n",
        "##### example format : https://www.woolsboutiqueuomo.com\n",
        "\n"
      ],
      "metadata": {
        "id": "oCNBPkRBbiU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "products_df, store_url = FindAlternateGroups('https://berkehome.pl')\n",
        "#products_df, store_url = products_df, 'https://sartale2022.myshopify.com'\n",
        "products_df = get_prod_dataframe(products_df, store_url)\n",
        "vect_df = get_df_vectorized(products_df)\n",
        "min_k = 2\n",
        "max_k = ceil(len(products_df)/3)\n",
        "k_value = get_best_of_k(min_k, max_k, vect_df)\n",
        "\n",
        "kmeans = KMeans(\n",
        "          n_clusters=k_value,\n",
        "          max_iter=100,\n",
        "          n_init='auto',\n",
        "          random_state=1234,\n",
        "      ).fit(vect_df)\n",
        "\n",
        "products_df['cluster_id'] = pd.Series(kmeans.labels_)\n",
        "\n",
        "alternate_dict = get_clustering_dict(products_df)\n",
        "\n",
        "print(alternate_dict)"
      ],
      "metadata": {
        "id": "Qt_bbfce-GDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alternate_dict"
      ],
      "metadata": {
        "id": "Fd_00RBDWE48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (Optional code to export clustered json as txt file)"
      ],
      "metadata": {
        "id": "u1DydPjdZUIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#optional code to export json\n",
        "\n",
        "\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/alternate groups/berkehome.txt\", 'w') as f: \n",
        "    for key, value in alternate_dict.items(): \n",
        "        f.write('%s:%s\\n' % (key, value))"
      ],
      "metadata": {
        "id": "k9xIFYQHluC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip freeze '/content/drive/MyDrive/Colab Notebooks/Alternate Groups/requirements.txt'"
      ],
      "metadata": {
        "id": "eHq1DJGcWnt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w9mbxNhHYibH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}